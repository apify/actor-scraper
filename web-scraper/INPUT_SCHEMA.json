{
    "title": "Web Scraper Input",
    "type": "object",
    "description": "Web Scraper loads <b>Start URLs</b> in the Chrome browser and executes <b>Page function</b> on each page to extract data from it. To follow links and scrape additional pages, set <b>Link selector</b> with <b>Pseudo-URLs</b> to specify which links to follow. Alternatively, you can manually enqueue new links in <b>Page function</b>. For details, see actor's <a href='https://apify.com/apify/web-scraper' target='_blank' rel='noopener'>README</a> or <a href='https://apify.com/docs/scraping/tutorial/introduction' target='_blank' rel='noopener'>Web scraping tutorial</a> in the Apify documentation.",
    "schemaVersion": 1,
    "properties": {
        "runMode": {
            "sectionCaption": "Basic configuration",
            "title": "Run mode",
            "type": "string",
            "description": "This property indicates the scraper's mode of operation. In DEVELOPMENT mode, the scraper ignores page timeouts, doesn't use sessionPool, opens pages one by one and enables debugging via Chrome DevTools.  Open the live view tab or the container URL to access the debugger. Further debugging options can be configured in the Advanced configuration section. PRODUCTION mode disables debugging and enables timeouts and concurrency. <br><br>For details, see <a href='https://apify.com/apify/web-scraper#run-mode' target='_blank' rel='noopener'>Run mode</a> in README.",
            "default": "PRODUCTION",
            "prefill": "DEVELOPMENT",
            "editor": "select",
            "enum": [
                "PRODUCTION",
                "DEVELOPMENT"
            ]
        },
        "startUrls": {
            "title": "Start URLs",
            "type": "array",
            "description": "URLs to begin scraping. <br><br>For details, see <a href='https://apify.com/apify/web-scraper#start-urls' target='_blank' rel='noopener'>Start URLs</a>",
            "prefill": [
                { "url": "https://www.leboncoin.fr/recherche?category=21&text=mer&price=17-50" }
            ],
            "editor": "requestListSources"
        },
        "proxyConfiguration": {
            "sectionCaption": "Proxy and browser configuration",
            "title": "Proxy must be FRENCH",
            "type": "object",
            "description": "Proxy servers to look as a FRENCH person, otherwise leboncoin will block you.<br><br>For details, see <a href='https://apify.com/apify/web-scraper#proxy-configuration' target='_blank' rel='noopener'>Proxy configuration</a>. Should look like this : 'http://groups-RESIDENTIAL,country-FR:mmmdWt2t3Q83GNxTiuuyCZCghh@proxy.apify.com:8000' ",
            "prefill": { "useApifyProxy": false },
            "default": { "useApifyProxy": false },
            "editor": "proxy"
        },
        "maxPagesPerCrawl": {
            "title": "Max pages",
            "type": "integer",
            "description": "Maximum number of pages that the scraper will load. It will stop when this limit is reached (prevent excess platform usage for misconfigured scrapers).<br><br>If <code>0</code>, there is no limit.",
            "minimum": 0,
            "default": 0
        },
        "maxCrawlingDepth": {
            "title": "Max clicking depth",
            "type": "integer",
            "description": "How many links away from <b>Start URLs</b> the scraper will click on (=> avoid infinite crawling). <br><br>If <code>0</code>, there is no limit.",
            "minimum": 0,
            "default": 3
        },
        "pseudoUrls": {
            "sectionCaption": "Advanced configuration",
            "title": "Pseudo-URLs",
            "type": "array",
            "description": "Specifies what kind of URLs found by <b>Link selector</b> should be added to the request queue. A pseudo-URL is a URL with regular expressions enclosed in <code>[]</code> brackets, e.g. <code>http://www.example.com/[.*]</code>. <br><br>If <b>Pseudo-URLs</b> are omitted, the actor enqueues all links matched by the <b>Link selector</b>.<br><br>For details, see <a href='https://apify.com/apify/web-scraper#pseudo-urls' target='_blank' rel='noopener'>Pseudo-URLs</a> in README.",
            "editor": "pseudoUrls",
            "prefill": [
                {
                    "purl": "https://www.leboncoin.fr[.*]"
                }
            ]
        },
        "pageFunction": {
            "title": "Function",
            "type": "string",
            "description": "JavaScript function executed on every page (inside the Chrome browser). Customise it if necessary. <br><br>For details, see <a href='https://apify.com/apify/web-scraper#page-function' target='_blank' rel='noopener'>Page function</a>",
            "prefill": "// For a complete list of its properties and functions,\n// see https://apify.com/apify/web-scraper#page-function \nasync function pageFunction(context) {\n    const $ = context.jQuery;\n    const pageTitle = $('title').first().text();\n    \n    let items = []\n    $('[data-qa-id=aditem_container]').map( function(i){\n        let obj = {}\n        obj.link = $(this).attr('href')\n        obj.img = $(this).find('img').attr('src')\n        obj.title = $(this).find('[data-qa-id=aditem_title]').text()\n        obj.price = $(this).find('[data-qa-id=aditem_price]').text()\n        items.push( JSON.parse(JSON.stringify(obj)) )\n    })\n\n    // Print some information to actor log\n    context.log.info(`URL: ${context.request.url}, TITLE: ${pageTitle}`);\n\n    return {\n        url: context.request.url,\n        items\n    };\n}",
            "editor": "javascript"            
        }
    },
    "required": ["startUrls", "pageFunction", "proxyConfiguration"]
}
